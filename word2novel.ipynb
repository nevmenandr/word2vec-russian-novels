{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Word2vec novels\n",
    "\n",
    "Векторные романы: код для рерайтинга произведений русской литературы, развлекательного проекта [Бориса Орехова](http://nevmenandr.net/bo.php)\n",
    "\n",
    "[Статья на Хабре](https://habr.com/ru/post/326380/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Slow version of gensim.models.doc2vec is being used\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import re\n",
    "import gensim\n",
    "import pymorphy2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = gensim.models.KeyedVectors.load_word2vec_format(\"ruwikiruscorpora_0_300_20.bin.gz\", binary=True)\n",
    "model.init_sims(replace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "morph = pymorphy2.MorphAnalyzer()\n",
    "punct = re.compile('^(.*?)([а-яА-ЯёЁ-]+)(.*?)$')\n",
    "capit = re.compile('^[А-Я]+$')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "pth_source = 'books_before/'\n",
    "lst = os.listdir(pth_source)\n",
    "\n",
    "pth_result = 'books_after/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cotags = {'ADJF':'ADJ', # pymorphy2: word2vec \n",
    "'ADJS' : 'ADJ', \n",
    "'ADVB' : 'ADV', \n",
    "'COMP' : 'ADV', \n",
    "'GRND' : 'VERB', \n",
    "'INFN' : 'VERB', \n",
    "'NOUN' : 'NOUN', \n",
    "'PRED' : 'ADV', \n",
    "'PRTF' : 'ADJ', \n",
    "'PRTS' : 'VERB', \n",
    "'VERB' : 'VERB'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(ord('А'))\n",
    "#print(ord('Я'))\n",
    "#print(ord('Ё'))\n",
    "capit_letters = [chr(x) for x in range(1040,1072)] + ['Ё']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### todo\n",
    "\n",
    "* ~~capitalize~~\n",
    "* ~~pos detection~~\n",
    "* ~~cashing of word2vec queries~~\n",
    "* ~~1st form extraction from pymorphy2 parse of word2vec response~~\n",
    "* ~~pos matching for most similar words~~\n",
    "* ~~names detection and excluding from the process~~\n",
    "* ~~agreement in gender~~\n",
    "* ~~yo-fication~~\n",
    "* ~~voice~~"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def search_neighbour(word, pos, gend='masc'):\n",
    "    word = word.replace('ё', 'е')\n",
    "    lex = word + '_' + cotags[pos]\n",
    "    if lex in model:\n",
    "        neighbs = model.most_similar([lex], topn=20)\n",
    "        for nei in neighbs:\n",
    "            lex_n, ps_n = nei[0].split('_')\n",
    "            if '::' in lex_n:\n",
    "                continue\n",
    "            if cotags[pos] == ps_n:\n",
    "                if pos == 'NOUN':\n",
    "                    parse_result = morph.parse(lex_n)\n",
    "                    for ana in parse_result:\n",
    "                        if ana.normal_form == lex_n:\n",
    "                            if ana.tag.gender == gend:\n",
    "                                return lex_n\n",
    "                elif cotags[pos] == 'VERB' and word[-2:] == 'ся':\n",
    "                    if lex_n[-2:] == 'ся':\n",
    "                        return lex_n\n",
    "                elif cotags[pos] == 'VERB' and word[-2:] != 'ся':\n",
    "                    if lex_n[-2:] != 'ся':\n",
    "                        return lex_n\n",
    "                else:\n",
    "                    return lex_n\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def flection(lex_neighb, tags):\n",
    "    tags = str(tags)\n",
    "    tags = re.sub(',[AGQSPMa-z-]+? ', ',', tags)\n",
    "    tags = tags.replace(\"impf,\", \"\")\n",
    "    tags = re.sub('([A-Z]) (plur|masc|femn|neut|inan)', '\\\\1,\\\\2', tags)\n",
    "    tags = tags.replace(\"Impe neut\", \"\")\n",
    "    tags = tags.split(',')\n",
    "    tags_clean = []\n",
    "    for t in tags:\n",
    "        if t:\n",
    "            if ' ' in t:\n",
    "                t1, t2 = t.split(' ')\n",
    "                t = t2\n",
    "            tags_clean.append(t)\n",
    "    tags = frozenset(tags_clean)\n",
    "    prep_for_gen = morph.parse(lex_neighb)\n",
    "    ana_array = []\n",
    "    for ana in prep_for_gen:\n",
    "        if ana.normal_form == lex_neighb:\n",
    "            ana_array.append(ana)\n",
    "    for ana in ana_array:\n",
    "        try:\n",
    "            flect = ana.inflect(tags)\n",
    "        except:\n",
    "            print(tags)\n",
    "            return None\n",
    "        if flect:\n",
    "            word_to_replace = flect.word\n",
    "            return word_to_replace\n",
    "    return None   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('теплый_ADJ', 0.6912842392921448),\n",
       " ('холод_NOUN', 0.6222048997879028),\n",
       " ('прохладный_ADJ', 0.6178681254386902),\n",
       " ('влажный_ADJ', 0.6009092926979065),\n",
       " ('жаркий_ADJ', 0.5878441333770752),\n",
       " ('горячий_ADJ', 0.5811808109283447),\n",
       " ('ледяной_ADJ', 0.5738131999969482),\n",
       " ('сухой_ADJ', 0.5681436657905579),\n",
       " ('сырой_ADJ', 0.5447033643722534),\n",
       " ('холодно_ADV', 0.5389620661735535),\n",
       " ('студеный_ADJ', 0.5354037880897522),\n",
       " ('морозный_ADJ', 0.5059537887573242),\n",
       " ('мокрый_ADJ', 0.49825477600097656),\n",
       " ('холодить_VERB', 0.49614548683166504),\n",
       " ('стыть_VERB', 0.49345287680625916),\n",
       " ('промозглый_ADJ', 0.49259310960769653),\n",
       " ('остыть_VERB', 0.4923018217086792),\n",
       " ('мягкий_ADJ', 0.4906276762485504),\n",
       " ('темный_ADJ', 0.48891666531562805),\n",
       " ('согревать_VERB', 0.4849362075328827)]"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.most_similar(['холодный_ADJ'], topn=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EugeneOnegin_JOF.txt\n",
      "FathersAndSons_JOF.txt\n",
      "WarAndPeace_JOF.txt\n",
      "MasterAndMargarita_JOF.txt\n",
      "CrimeAndPunishment_JOF.txt\n"
     ]
    }
   ],
   "source": [
    "cash_neighb = {}\n",
    "\n",
    "for fl in lst:\n",
    "    if not fl.endswith('_JOF.txt'):\n",
    "        continue\n",
    "    print (fl)\n",
    "    i = 0\n",
    "    f = open(pth_source + fl, 'r', encoding='utf-8')\n",
    "    fw = open(pth_result + '3.0_' + fl, 'w', encoding='utf-8')\n",
    "    fs = open(pth_result + '3.0_Sample' + fl, 'w', encoding='utf-8')\n",
    "    for line in f:\n",
    "        new_line = []\n",
    "        i += 1\n",
    "        line = line.strip()\n",
    "        words = line.split(' ')\n",
    "        for word in words:\n",
    "            struct = punct.findall(word)\n",
    "            if struct:\n",
    "                struct = struct[0]\n",
    "            else:\n",
    "                new_line.append(word)\n",
    "                continue\n",
    "            #print (struct)\n",
    "            wordform = struct[1]\n",
    "            if wordform:\n",
    "                if capit.search(wordform):\n",
    "                    new_line.append(word)\n",
    "                    continue\n",
    "                else:\n",
    "                    if wordform[0] in capit_letters:\n",
    "                        capit_flag = 1\n",
    "                    else:\n",
    "                        capit_flag = 0\n",
    "                parse_result = morph.parse(wordform)[0]\n",
    "                if 'Name' in parse_result.tag or 'Patr' in parse_result.tag:\n",
    "                    new_line.append(word)\n",
    "                    continue\n",
    "                if parse_result.normal_form == 'глава':\n",
    "                    new_line.append(word)\n",
    "                    continue\n",
    "                pos_flag = 0\n",
    "                for tg in cotags:\n",
    "                    if tg in parse_result.tag:\n",
    "                        pos_flag = 1\n",
    "                        lex = parse_result.normal_form\n",
    "                        pos_tag = parse_result.tag.POS\n",
    "                        if (lex, pos_tag) in cash_neighb:\n",
    "                            lex_neighb = cash_neighb[(lex, pos_tag)]\n",
    "                        else:\n",
    "                            if pos_tag == 'NOUN':\n",
    "                                gen_tag = parse_result.tag.gender\n",
    "                                lex_neighb = search_neighbour(lex, pos_tag, gend=gen_tag)\n",
    "                            else:\n",
    "                                lex_neighb = search_neighbour(lex, pos_tag)\n",
    "                            cash_neighb[(lex, pos_tag)] = lex_neighb\n",
    "                        if not lex_neighb:\n",
    "                            new_line.append(word)\n",
    "                            break\n",
    "                        else:\n",
    "                            if pos_tag == 'NOUN':\n",
    "                                if parse_result.tag.case == 'nomn' and parse_result.tag.number == 'sing':\n",
    "                                    if capit_flag == 1:\n",
    "                                        lex_neighb = lex_neighb.capitalize()\n",
    "                                    new_line.append(struct[0] + lex_neighb + struct[2])\n",
    "                                else:\n",
    "                                    word_to_replace = flection(lex_neighb, parse_result.tag)\n",
    "                                    if word_to_replace:\n",
    "                                        if capit_flag == 1:\n",
    "                                            word_to_replace = word_to_replace.capitalize()\n",
    "                                        new_line.append(struct[0] + word_to_replace + struct[2])\n",
    "                                    else:\n",
    "                                        new_line.append(word)\n",
    "                                    \n",
    "                            elif pos_tag == 'ADJF':\n",
    "                                if parse_result.tag.case == 'nomn' and parse_result.tag.number == 'sing':\n",
    "                                    if capit_flag == 1:\n",
    "                                        lex_neighb = lex_neighb.capitalize()\n",
    "                                    new_line.append(struct[0] + lex_neighb + struct[2])\n",
    "                                else:\n",
    "                                    word_to_replace = flection(lex_neighb, parse_result.tag)\n",
    "                                    if word_to_replace:\n",
    "                                        if capit_flag == 1:\n",
    "                                            word_to_replace = word_to_replace.capitalize()\n",
    "                                        new_line.append(struct[0] + word_to_replace + struct[2])\n",
    "                                    else:\n",
    "                                        new_line.append(word)\n",
    "                            \n",
    "                            elif pos_tag == 'INFN':\n",
    "                                if capit_flag == 1:\n",
    "                                    lex_neighb = lex_neighb.capitalize()\n",
    "                                new_line.append(struct[0] + lex_neighb + struct[2])\n",
    "                            \n",
    "                            elif pos_tag in ['ADVB', 'COMP', 'PRED']:\n",
    "                                if capit_flag == 1:\n",
    "                                    lex_neighb = lex_neighb.capitalize()\n",
    "                                new_line.append(struct[0] + lex_neighb + struct[2])\n",
    "                                \n",
    "                            else:\n",
    "                                word_to_replace = flection(lex_neighb, parse_result.tag)\n",
    "                                if word_to_replace:\n",
    "                                    if capit_flag == 1:\n",
    "                                        word_to_replace = word_to_replace.capitalize()\n",
    "                                    new_line.append(struct[0] + word_to_replace + struct[2])\n",
    "                                else:\n",
    "                                    new_line.append(word)\n",
    "                        break\n",
    "                if pos_flag == 0:\n",
    "                    new_line.append(word)\n",
    "            else:\n",
    "                new_line.append(''.join(struct))\n",
    "        line_replace = ' '.join(new_line)\n",
    "        if i < 21:\n",
    "            fs.write(line_replace + '\\n')\n",
    "        fw.write(line_replace + '\\n')\n",
    "    f.close()\n",
    "    fw.close()\n",
    "    fs.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Анна Каренина\n",
    "### Отдельно по частям речи"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pth_source = 'AK/'\n",
    "lst = os.listdir(pth_source)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def appending(new_line, word):\n",
    "    for k in new_line:\n",
    "        new_line[k].append(word)\n",
    "    return new_line"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AnnaKarenina.txt\n"
     ]
    }
   ],
   "source": [
    "cash_neighb = {}\n",
    "\n",
    "for fl in lst:\n",
    "    print (fl)\n",
    "    flc = fl.replace('.txt', '.tsv')\n",
    "    i = 0\n",
    "    f = open(pth_source + fl, 'r', encoding='utf-8')\n",
    "    fw = open(pth_result + flc, 'w', encoding='utf-8')\n",
    "    fs = open(pth_result + 'NOUN_' + flc, 'w', encoding='utf-8')\n",
    "    fv = open(pth_result + 'VERB_' + flc, 'w', encoding='utf-8')\n",
    "    for fh in [fw, fs, fv]:\n",
    "        fh.write('Оригинал\\tПотенциальный текст\\n')\n",
    "    for line in f:\n",
    "        new_line = {'ALL': [], 'NOUN': [], 'VERB': []}\n",
    "        i += 1\n",
    "        line = line.strip()\n",
    "        line = line.replace('\\t', ' ')\n",
    "        words = line.split(' ')\n",
    "        for word in words:\n",
    "            struct = punct.findall(word)\n",
    "            if struct:\n",
    "                struct = struct[0]\n",
    "            else:\n",
    "                new_line = appending(new_line, word)\n",
    "                continue\n",
    "            #print (struct)\n",
    "            wordform = struct[1]\n",
    "            if wordform:\n",
    "                if capit.search(wordform):\n",
    "                    new_line = appending(new_line, word)\n",
    "                    continue\n",
    "                else:\n",
    "                    if wordform[0] in capit_letters:\n",
    "                        capit_flag = 1\n",
    "                    else:\n",
    "                        capit_flag = 0\n",
    "                parse_result = morph.parse(wordform)[0]\n",
    "                if 'Name' in parse_result.tag or 'Patr' in parse_result.tag:\n",
    "                    new_line = appending(new_line, word)\n",
    "                    continue\n",
    "                if parse_result.normal_form == 'глава':\n",
    "                    new_line = appending(new_line, word)\n",
    "                    continue\n",
    "                pos_flag = 0\n",
    "                for tg in cotags:\n",
    "                    if tg in parse_result.tag:\n",
    "                        pos_flag = 1\n",
    "                        lex = parse_result.normal_form\n",
    "                        pos_tag = parse_result.tag.POS\n",
    "                        if (lex, pos_tag) in cash_neighb:\n",
    "                            lex_neighb = cash_neighb[(lex, pos_tag)]\n",
    "                        else:\n",
    "                            if pos_tag == 'NOUN':\n",
    "                                gen_tag = parse_result.tag.gender\n",
    "                                lex_neighb = search_neighbour(lex, pos_tag, gend=gen_tag)\n",
    "                            else:\n",
    "                                lex_neighb = search_neighbour(lex, pos_tag)\n",
    "                            cash_neighb[(lex, pos_tag)] = lex_neighb\n",
    "                        if not lex_neighb:\n",
    "                            new_line = appending(new_line, word)\n",
    "                            break\n",
    "                        else:\n",
    "                            if pos_tag == 'NOUN':\n",
    "                                if parse_result.tag.case == 'nomn' and parse_result.tag.number == 'sing':\n",
    "                                    if capit_flag == 1:\n",
    "                                        lex_neighb = lex_neighb.capitalize()\n",
    "                                    new_line['ALL'].append(struct[0] + lex_neighb + struct[2])\n",
    "                                    new_line['NOUN'].append(struct[0] + lex_neighb + struct[2])\n",
    "                                    new_line['VERB'].append(word)\n",
    "                                else:\n",
    "                                    word_to_replace = flection(lex_neighb, parse_result.tag)\n",
    "                                    if word_to_replace:\n",
    "                                        if capit_flag == 1:\n",
    "                                            word_to_replace = word_to_replace.capitalize()\n",
    "                                        new_line['ALL'].append(struct[0] + word_to_replace + struct[2])\n",
    "                                        new_line['NOUN'].append(struct[0] + word_to_replace + struct[2])\n",
    "                                        new_line['VERB'].append(word)\n",
    "                                    else:\n",
    "                                        new_line = appending(new_line, word)\n",
    "                                    \n",
    "                            elif pos_tag == 'ADJF':\n",
    "                                if parse_result.tag.case == 'nomn' and parse_result.tag.number == 'sing':\n",
    "                                    if capit_flag == 1:\n",
    "                                        lex_neighb = lex_neighb.capitalize()\n",
    "                                    new_line['ALL'].append(struct[0] + lex_neighb + struct[2])\n",
    "                                    new_line['NOUN'].append(struct[0] + lex_neighb + struct[2])\n",
    "                                    new_line['VERB'].append(word)\n",
    "                                else:\n",
    "                                    word_to_replace = flection(lex_neighb, parse_result.tag)\n",
    "                                    if word_to_replace:\n",
    "                                        if capit_flag == 1:\n",
    "                                            word_to_replace = word_to_replace.capitalize()\n",
    "                                        new_line['ALL'].append(struct[0] + word_to_replace + struct[2])\n",
    "                                        new_line['NOUN'].append(struct[0] + word_to_replace + struct[2])\n",
    "                                        new_line['VERB'].append(word)\n",
    "                                    else:\n",
    "                                        new_line = appending(new_line, word)\n",
    "                            \n",
    "                            elif pos_tag == 'INFN':\n",
    "                                if capit_flag == 1:\n",
    "                                    lex_neighb = lex_neighb.capitalize()\n",
    "                                new_line['ALL'].append(struct[0] + lex_neighb + struct[2])\n",
    "                                new_line['VERB'].append(struct[0] + lex_neighb + struct[2])\n",
    "                                new_line['NOUN'].append(word)\n",
    "                            \n",
    "                            elif pos_tag in ['ADVB', 'COMP', 'PRED']:\n",
    "                                if capit_flag == 1:\n",
    "                                    lex_neighb = lex_neighb.capitalize()\n",
    "                                new_line['ALL'].append(struct[0] + lex_neighb + struct[2])\n",
    "                                new_line['NOUN'].append(word)\n",
    "                                new_line['VERB'].append(word)\n",
    "                            else:\n",
    "                                word_to_replace = flection(lex_neighb, parse_result.tag)\n",
    "                                if word_to_replace:\n",
    "                                    if capit_flag == 1:\n",
    "                                        word_to_replace = word_to_replace.capitalize()\n",
    "                                    if cotags[pos_tag] == 'VERB':\n",
    "                                        new_line['ALL'].append(struct[0] + word_to_replace + struct[2])\n",
    "                                        new_line['VERB'].append(struct[0] + word_to_replace + struct[2])\n",
    "                                        new_line['NOUN'].append(word)\n",
    "                                    elif cotags[pos_tag] == 'ADJ':\n",
    "                                        new_line['ALL'].append(struct[0] + word_to_replace + struct[2])\n",
    "                                        new_line['NOUN'].append(struct[0] + word_to_replace + struct[2])\n",
    "                                        new_line['VERB'].append(word)\n",
    "                                    #new_line.append(struct[0] + word_to_replace + struct[2])\n",
    "                                else:\n",
    "                                    new_line = appending(new_line, word)\n",
    "                        break\n",
    "                if pos_flag == 0:\n",
    "                    new_line = appending(new_line, word)\n",
    "            else:\n",
    "                new_line = appending(new_line, ''.join(struct))\n",
    "        line_replace = ' '.join(new_line['ALL'])\n",
    "        fw.write(line + '\\t' + line_replace + '\\n')\n",
    "        line_replace = ' '.join(new_line['NOUN'])\n",
    "        fs.write(line + '\\t' + line_replace + '\\n')\n",
    "        line_replace = ' '.join(new_line['VERB'])\n",
    "        fv.write(line + '\\t' + line_replace + '\\n')\n",
    "    f.close()\n",
    "    fw.close()\n",
    "    fs.close()\n",
    "    fv.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Произведения школьной программы"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "StaruhaIzergil.txt\n",
      "VishnevyjSad.txt\n",
      "BednajaLiza.txt\n",
      "PovestiBelkina.txt\n",
      "AlenkijCvetochek.txt\n",
      "PervajaLyubov.txt\n",
      "GerojNashegoVremeni.txt\n",
      "KapitanskayaDochka.txt\n",
      "Nos.txt\n",
      "Revizor.txt\n",
      "Nedorosl.txt\n",
      "Asya.txt\n",
      "MocartISaljeri.txt\n",
      "Oblomov.txt\n",
      "TriSestry.txt\n",
      "PalataNomer6.txt\n",
      "GoreOtUma.txt\n",
      "Mcyri.txt\n",
      "Shinel.txt\n",
      "KonekGorbunok.txt\n",
      "Chajka.txt\n",
      "SkazkaOCareSaltane.txt\n"
     ]
    }
   ],
   "source": [
    "pth_source = 'vector-school/'\n",
    "lst = os.listdir(pth_source)\n",
    "\n",
    "pth_result = 'vector-school-after/'\n",
    "\n",
    "cash_neighb = {}\n",
    "\n",
    "for fl in lst:\n",
    "    if not fl.endswith('.txt'):\n",
    "        continue\n",
    "    print (fl)\n",
    "    i = 0\n",
    "    f = open(pth_source + fl, 'r', encoding='utf-8')\n",
    "    fw = open(pth_result + 'vector_' + fl, 'w', encoding='utf-8')\n",
    "    fs = open(pth_result + 'Sample' + fl, 'w', encoding='utf-8')\n",
    "    for line in f:\n",
    "        new_line = []\n",
    "        i += 1\n",
    "        line = line.strip()\n",
    "        words = line.split(' ')\n",
    "        for word in words:\n",
    "            struct = punct.findall(word)\n",
    "            if struct:\n",
    "                struct = struct[0]\n",
    "            else:\n",
    "                new_line.append(word)\n",
    "                continue\n",
    "            #print (struct)\n",
    "            wordform = struct[1]\n",
    "            if wordform:\n",
    "                if capit.search(wordform):\n",
    "                    new_line.append(word)\n",
    "                    continue\n",
    "                else:\n",
    "                    if wordform[0] in capit_letters:\n",
    "                        capit_flag = 1\n",
    "                    else:\n",
    "                        capit_flag = 0\n",
    "                parse_result = morph.parse(wordform)[0]\n",
    "                if 'Name' in parse_result.tag or 'Patr' in parse_result.tag:\n",
    "                    new_line.append(word)\n",
    "                    continue\n",
    "                if parse_result.normal_form == 'глава':\n",
    "                    new_line.append(word)\n",
    "                    continue\n",
    "                pos_flag = 0\n",
    "                for tg in cotags:\n",
    "                    if tg in parse_result.tag:\n",
    "                        pos_flag = 1\n",
    "                        lex = parse_result.normal_form\n",
    "                        pos_tag = parse_result.tag.POS\n",
    "                        if (lex, pos_tag) in cash_neighb:\n",
    "                            lex_neighb = cash_neighb[(lex, pos_tag)]\n",
    "                        else:\n",
    "                            if pos_tag == 'NOUN':\n",
    "                                gen_tag = parse_result.tag.gender\n",
    "                                lex_neighb = search_neighbour(lex, pos_tag, gend=gen_tag)\n",
    "                            else:\n",
    "                                lex_neighb = search_neighbour(lex, pos_tag)\n",
    "                            cash_neighb[(lex, pos_tag)] = lex_neighb\n",
    "                        if not lex_neighb:\n",
    "                            new_line.append(word)\n",
    "                            break\n",
    "                        else:\n",
    "                            if pos_tag == 'NOUN':\n",
    "                                if parse_result.tag.case == 'nomn' and parse_result.tag.number == 'sing':\n",
    "                                    if capit_flag == 1:\n",
    "                                        lex_neighb = lex_neighb.capitalize()\n",
    "                                    new_line.append(struct[0] + lex_neighb + struct[2])\n",
    "                                else:\n",
    "                                    word_to_replace = flection(lex_neighb, parse_result.tag)\n",
    "                                    if word_to_replace:\n",
    "                                        if capit_flag == 1:\n",
    "                                            word_to_replace = word_to_replace.capitalize()\n",
    "                                        new_line.append(struct[0] + word_to_replace + struct[2])\n",
    "                                    else:\n",
    "                                        new_line.append(word)\n",
    "                                    \n",
    "                            elif pos_tag == 'ADJF':\n",
    "                                if parse_result.tag.case == 'nomn' and parse_result.tag.number == 'sing':\n",
    "                                    if capit_flag == 1:\n",
    "                                        lex_neighb = lex_neighb.capitalize()\n",
    "                                    new_line.append(struct[0] + lex_neighb + struct[2])\n",
    "                                else:\n",
    "                                    word_to_replace = flection(lex_neighb, parse_result.tag)\n",
    "                                    if word_to_replace:\n",
    "                                        if capit_flag == 1:\n",
    "                                            word_to_replace = word_to_replace.capitalize()\n",
    "                                        new_line.append(struct[0] + word_to_replace + struct[2])\n",
    "                                    else:\n",
    "                                        new_line.append(word)\n",
    "                            \n",
    "                            elif pos_tag == 'INFN':\n",
    "                                if capit_flag == 1:\n",
    "                                    lex_neighb = lex_neighb.capitalize()\n",
    "                                new_line.append(struct[0] + lex_neighb + struct[2])\n",
    "                            \n",
    "                            elif pos_tag in ['ADVB', 'COMP', 'PRED']:\n",
    "                                if capit_flag == 1:\n",
    "                                    lex_neighb = lex_neighb.capitalize()\n",
    "                                new_line.append(struct[0] + lex_neighb + struct[2])\n",
    "                                \n",
    "                            else:\n",
    "                                word_to_replace = flection(lex_neighb, parse_result.tag)\n",
    "                                if word_to_replace:\n",
    "                                    if capit_flag == 1:\n",
    "                                        word_to_replace = word_to_replace.capitalize()\n",
    "                                    new_line.append(struct[0] + word_to_replace + struct[2])\n",
    "                                else:\n",
    "                                    new_line.append(word)\n",
    "                        break\n",
    "                if pos_flag == 0:\n",
    "                    new_line.append(word)\n",
    "            else:\n",
    "                new_line.append(''.join(struct))\n",
    "        line_replace = ' '.join(new_line)\n",
    "        if i < 21:\n",
    "            fs.write(line_replace + '\\n')\n",
    "        fw.write(line_replace + '\\n')\n",
    "    f.close()\n",
    "    fw.close()\n",
    "    fs.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
